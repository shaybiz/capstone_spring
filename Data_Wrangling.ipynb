{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset and Data Wrangling:\n",
    "The data used in this study includes natality (birth data) and fatality (death data) files of infants born in the year 2008 accompanied by a pdf-formatted document that describes the data content and type. The birth cohort data for 2008 consists of infant deaths that occurred in 2008 or 2009 linked to births in 2008. The data also includes a separate file that includes infant deaths, unlinked file, which had not been linked to a corresponding record in the natality file. \n",
    "\n",
    "The guide document was converted into usable format in two steps. \n",
    "\n",
    "First, Tabula, service software, was used to convert the guide document from pdf to tsv (tab separated values file) format. The tsv file was then reformatted using python\n",
    "\n",
    "The original data set did not have column names and it required a second step of writing a python code to extract the field names from the accompanying guide document. \n",
    "\n",
    "An exploratory data assessment shows the number of fields and type of some of the fields has changed over the years. Although the original plan was to work with data from 1995 to 2010, I made the decision of working with the 2008 data \n",
    "(4 million plus records) for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function extracts only the necessary attribute information (the name of the attribute and its poistion in the data) from the guide file and reformats it for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "import re\n",
    "def format_cols():\n",
    "    cols_in = codecs.open('2005/tabula_2005','r','utf-8')\n",
    "    file_out=open('2005/format_out','w+')\n",
    "    for lines in cols_in:\n",
    "        try:\n",
    "            cols = lines.split()\n",
    "            if (re.match(\"^[0-9]\",cols[0]) and (re.match(\"FILLER\",cols[2]) is None) and (re.match(\"[A-Z][A-Z]\",cols[2]) is not None)):\n",
    "                file_out.write(cols[0] + '\\t' + cols[1] + '\\t' + cols[2] + '\\n')\n",
    "            elif (re.match('\\\"',cols[0]) and (re.match(\"^[0-9]\",cols[1])) and (re.match(\"^[0-9]\",cols[2])) and (re.match(\"[A-Z][A-Z]\",cols[3]) is not None)):\n",
    "                file_out.write(cols[1] + '\\t' + cols[2] + '\\t' + cols[3] + '\\n')\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "#format_cols()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function extracts the position of each attribute from the reformatted and cleaned data guide file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_yearList = [2008]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def instfile():\n",
    "    global data_yearList\n",
    "    for yr in data_yearList:\n",
    "        path_name = os.path.join('ReadingData/',str(yr),'new_format')\n",
    "        infile = open(path_name,'r')\n",
    "        outfile = open('%s.out.txt' % yr,'w+')\n",
    "        outfile2 = open('%s.out2.txt' % yr,'w+')\n",
    "        ou3 = open('%s.colname' % yr,'w+')\n",
    "   \n",
    "        for lines in infile:\n",
    "            c1 = re.split('\\t',lines)[0].replace(\"-\",\",\")\n",
    "            x = int(re.split(',',c1)[0]) - 1 \n",
    "            x = str(x)\n",
    "            try:\n",
    "                y = re.split(',',c1)[1]\n",
    "            except IndexError:\n",
    "                y = int(re.split(',',c1)[0]) \n",
    "                y = str(y)\n",
    "                \n",
    "            #print(x,y)\n",
    "            c2 = re.split('\\t',lines)[2]\n",
    "            outfile.write(x + \"\\n\")\n",
    "            outfile2.write(y + \"\\n\")\n",
    "            ou3.write(c2 + \"\\n\")\n",
    "    return x,y\n",
    "    #return c1, c2\n",
    "#[c1,c2]=instfile()\n",
    "[x,y]=instfile()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function builds a data frame using the attribute information (from the guide file) and the actual data. \n",
    "It has the capability of building a dictionary for multiple years if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReadingData/2008/LinkCO08USDen.dat\n"
     ]
    }
   ],
   "source": [
    "#sam_year = [1995,1996]\n",
    "def build_dict(yr):\n",
    "    fname = str(yr) + '/LinkCO' + str(yr)[2:4] + 'USDen.dat'\n",
    "    #path_name = os.path.abspath('ReadingData/' + str(yr) + fname)\n",
    "    path_name = os.path.join('ReadingData/',fname)\n",
    "    print(path_name)\n",
    "    infl = pd.read_table(path_name,'r',header=None)\n",
    "    ofl1=pd.read_csv('%s.out.txt' % yr,'r',header=None)\n",
    "    ofl2=pd.read_csv('%s.out2.txt' % yr,'r',header=None)\n",
    "    ofl3=pd.read_csv('%s.colname' % yr,'r',header=None)\n",
    "    a_name = 'a_{}'.format(yr) \n",
    "    a_name = {}\n",
    "    for ind in range(len(ofl3.index)):\n",
    "        a_name[ofl3[0][ind]]=(infl.iloc[:,0].str.slice(ofl1.iat[ind,0],ofl2.iat[ind,0]))\n",
    "    df = pd.DataFrame(a_name)\n",
    "    return df\n",
    "\n",
    "yrList = [2008]\n",
    "def dict_all(yrList):\n",
    "    d={}\n",
    "    for yr in yrList:\n",
    "        d['%s' % yr] = build_dict(yr)\n",
    "    return d\n",
    "dd = dict_all(yrList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The data is now ready for the next step of exploratory data analysis (EDA). We may come back to the data wrangling process if we decide any reformatting makes the data analysis part easier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AB_ANTI       0\n",
      "AB_AVEN1      0\n",
      "AB_AVEN6      0\n",
      "AB_BINJ       0\n",
      "AB_NICU       0\n",
      "AB_SEIZ       0\n",
      "AB_SURF       0\n",
      "AGED          0\n",
      "AGER22        0\n",
      "AGER5         0\n",
      "APGAR5        0\n",
      "APGAR5R       0\n",
      "ATTEND        0\n",
      "AUTOPSY       0\n",
      "BFACIL        0\n",
      "BFACIL3       0\n",
      "BRTHWGT       0\n",
      "BWTIMP        0\n",
      "BWTR14        0\n",
      "BWTR4         0\n",
      "CA_ANEN       0\n",
      "CA_CCHD       0\n",
      "CA_CDH        0\n",
      "CA_CLEFT      0\n",
      "CA_CLPAL      0\n",
      "CA_DISOR      0\n",
      "CA_DOWN       0\n",
      "CA_GAST       0\n",
      "CA_HYPO       0\n",
      "CA_LIMB       0\n",
      "             ..\n",
      "UCA_DOWNS     0\n",
      "UCA_OMPHA     0\n",
      "UCA_SPINA     0\n",
      "UCIG_REC6     0\n",
      "UCODR130      0\n",
      "UDMETH_REC    0\n",
      "UFAGECOMB     0\n",
      "UFHISP        0\n",
      "UFRACE        0\n",
      "ULD_BREECH    0\n",
      "ULD_MECO      0\n",
      "ULD_PRECIP    0\n",
      "UMEDUC        0\n",
      "UME_FORCP     0\n",
      "UME_PRIMC     0\n",
      "UME_REPEC     0\n",
      "UME_VAC       0\n",
      "UME_VAG       0\n",
      "UME_VBAC      0\n",
      "UMHISP        0\n",
      "UOP_INDUC     0\n",
      "UOP_TOCOL     0\n",
      "UPREVIS       0\n",
      "URF_CHYPER    0\n",
      "URF_DIAB      0\n",
      "URF_ECLAM     0\n",
      "URF_PHYPER    0\n",
      "WEEKDAYD      0\n",
      "WTGAIN        0\n",
      "WTGAIN_REC    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def num_missing(col_or_row):\n",
    "    return sum(col_or_row.isnull())\n",
    "print(aa.apply(num_missing, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    " \n",
    "# Data to plot\n",
    "labels = '1', '2', '3', '4', '5'\n",
    "sizes = [23713, 49885, 480315, 3433278, 19852]\n",
    "colors = ['red','gold', 'yellowgreen', 'lightcoral', 'lightskyblue']\n",
    "explode = (0.1, 0, 0, 0,0)  # explode 1st slice\n",
    " \n",
    "# Plot\n",
    "plt.pie(sizes, explode=explode, labels=labels, colors=colors,\n",
    "        autopct='%1.1f%%', shadow=True, startangle=140)\n",
    " \n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sbisrat/anaconda/lib/python3.5/site-packages/matplotlib/tight_layout.py:222: UserWarning: tight_layout : falling back to Agg renderer\n",
      "  warnings.warn(\"tight_layout : falling back to Agg renderer\")\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    " \n",
    "labels = ['1', '2', '3', '4', '5']\n",
    "data1 = [23713, 49885, 480315, 3433278, 19852]\n",
    "data2= [9705, 3108, 4151, 6435, 774]\n",
    "colors = ['red','gold', 'yellowgreen', 'lightcoral', 'lightskyblue']\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "patches, texts = ax1.pie(data1, colors=colors, shadow=True, startangle=90)\n",
    "patches, texts = ax2.pie(data2, colors=colors, shadow=True, startangle=90)\n",
    "plt.legend(patches, labels, loc=\"best\")\n",
    "plt.axis('equal')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
